{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a82363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "581fe97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "train_file = 'data/train.jsonl'\n",
    "dev_file = 'data/dev.jsonl'\n",
    "wiki_pages_dir = 'data/wiki-pages/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc2da959-909b-4de4-80c1-1d227b9dc2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_wiki_entity_map = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b6879c-43f8-4220-a784-0f00a289658a",
   "metadata": {},
   "source": [
    "## Creating entity map for entire wiki-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be10b4c-a9bf-452b-80ff-7294f8cccbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_pages = glob.glob(os.path.join(wiki_pages_dir, '*.jsonl'))\n",
    "\n",
    "num_wiki_pages = len(wiki_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c655929-6ba8-4228-8e1e-c83e125bc518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abbda3b0-8d1d-4d32-8a00-c4ba43ec7357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e354af23f5c491a8a9b8661f90f0ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(num_wiki_pages)) : \n",
    "    \n",
    "    wiki_file = open(wiki_pages[i])\n",
    "    for line in wiki_file.readlines() : \n",
    "        data = json.loads(line)\n",
    "        wiki_dict[data['id']] = wiki_pages[i]\n",
    "    wiki_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e843444e-13bd-4009-a895-3b3cdf6953f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/entity-map.json', 'w') as f :\n",
    "    json.dump(wiki_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fec770-140c-4bf8-abab-3945523cac18",
   "metadata": {},
   "source": [
    "## Reading train.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3be6fda9-9ece-4527-86cd-85d4b3412cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_file) as f : \n",
    "    train_data = f.readlines()\n",
    "    \n",
    "num_train_data = len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f31f16a2-ec43-49c8-9d2c-56df8a84b23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145449"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5f05932-06c4-4c23-94f6-e776acb419ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(sample) :\n",
    "    \n",
    "    processed = {}\n",
    "    if sample['verifiable'] == 'VERIFIABLE' : \n",
    "        processed['claim'] = sample['claim']\n",
    "        processed['label'] = sample['label']\n",
    "        processed['evidence'] = {} \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for evidence in sample['evidence'][0] : \n",
    "\n",
    "            wiki_file = open(wiki_dict[evidence[2]]) \n",
    "\n",
    "            for line in wiki_file.readlines() : \n",
    "\n",
    "                line = json.loads(line)\n",
    "\n",
    "                if line['id'] == evidence[-2] : \n",
    "\n",
    "                    processed['evidence'][evidence[-2] + '_' + str(evidence[-1])] = {int(l.split('\\t')[0]):l.split('\\t')[1] for l in line['lines'].split('\\n')}\n",
    "                    \n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38049082-fcbf-4337-a51a-a889b8ff6967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'José_María_Chacón'\n",
      "'Régine_Chassagne'\n",
      "'Chris_Pérez'\n",
      "Finished processing : 500 samples.\n",
      "There are 270 samples that SUPPORTS.\n",
      "There are 97 samples that REFUTES.\n",
      "Time taken for last 500 iterations :  119.0964138507843\n",
      "'Beyoncé'\n",
      "'Frédéric_Auguste_Bartholdi'\n",
      "Finished processing : 1000 samples.\n",
      "There are 541 samples that SUPPORTS.\n",
      "There are 189 samples that REFUTES.\n",
      "Time taken for last 500 iterations :  112.17393589019775\n",
      "Finished processing : 1500 samples.\n",
      "There are 784 samples that SUPPORTS.\n",
      "There are 306 samples that REFUTES.\n",
      "Time taken for last 500 iterations :  111.08995008468628\n",
      "'Björn_Borg'\n",
      "Finished processing : 2000 samples.\n",
      "There are 1070 samples that SUPPORTS.\n",
      "There are 399 samples that REFUTES.\n",
      "Time taken for last 500 iterations :  120.7069571018219\n",
      "'Citadelle_Laferrière'\n",
      "Finished processing : 2500 samples.\n",
      "There are 1334 samples that SUPPORTS.\n",
      "There are 500 samples that REFUTES.\n",
      "Time taken for last 500 iterations :  117.71129989624023\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverifiable\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVERIFIABLE\u001b[39m\u001b[38;5;124m'\u001b[39m : \n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUPPORTS\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (num_supported\u001b[38;5;241m==\u001b[39mmax_num_supported) : \n\u001b[0;32m---> 21\u001b[0m         processed \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m         num_supported \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     23\u001b[0m         processed_samples\u001b[38;5;241m.\u001b[39mappend(processed)\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mprocess_sample\u001b[0;34m(sample)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m evidence \u001b[38;5;129;01min\u001b[39;00m sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevidence\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m] : \n\u001b[1;32m     14\u001b[0m     wiki_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(wiki_dict[evidence[\u001b[38;5;241m2\u001b[39m]]) \n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[43mwiki_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m : \n\u001b[1;32m     18\u001b[0m         line \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line)\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m line[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m evidence[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] : \n",
      "File \u001b[0;32m~/Projects/disco-fever/venv/lib/python3.8/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m--> 322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# keep undecoded input until the next call\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m=\u001b[39m data[consumed:]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "processed_samples = []\n",
    "num_supported = 0\n",
    "num_refuted = 0 \n",
    "\n",
    "max_num_supported = 25000\n",
    "max_num_refuted = 25000\n",
    "\n",
    "i = 0\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "while not (num_supported==max_num_supported) and not (num_refuted==max_num_refuted) : \n",
    "    \n",
    "    sample = json.loads(train_data[i])\n",
    "    \n",
    "    try : \n",
    "    \n",
    "        if sample['verifiable'] == 'VERIFIABLE' : \n",
    "            if (sample['label'] == 'SUPPORTS') and not (num_supported==max_num_supported) : \n",
    "                \n",
    "                processed = process_sample(sample)\n",
    "                num_supported += 1\n",
    "                processed_samples.append(processed)\n",
    "            \n",
    "            elif (sample['label'] == 'REFUTES') and not (num_refuted==max_num_refuted) :\n",
    "                \n",
    "                processed = process_sample(sample)\n",
    "                num_refuted += 1\n",
    "                processed_samples.append(processed)\n",
    "            \n",
    "        \n",
    "    except Exception as e: \n",
    "\n",
    "        print(e)\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "    if i%500 == 0 : \n",
    "        \n",
    "        print(\"Finished processing : {} samples.\".format(i))\n",
    "        print(\"There are {} samples that SUPPORTS.\".format(num_supported))\n",
    "        print(\"There are {} samples that REFUTES.\".format(num_refuted))\n",
    "        print(\"Time taken for last 500 iterations : \" , time.time() - start_time)\n",
    "        start_time = time.time()\n",
    "    \n",
    "    \n",
    "with open('data/processed_samples.json', 'w') as f : \n",
    "    json.dump(processed_samples, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fce879db-a636-4543-877a-fb5823f71cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not (num_supported==max_num_supported) and not  (num_refuted==max_num_refuted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0959f981-9185-4d3e-8c0b-0f1b850aa112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
